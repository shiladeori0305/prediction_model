# -*- coding: utf-8 -*-
"""prediction_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10efBldNvTvicv4yXUkXwO0gxcOXABO39
"""

!pip install streamlit pyngrok yfinance scikit-learn matplotlib --quiet

import yfinance as yf
import pandas as pd
import numpy as np

tickers = ["GLD", "SLV", "USO", "SPY", "DX-Y.NYB"]

data = yf.download(tickers, start="2012-01-01", end="2024-12-31")['Close']
data.head()

future_days = 10

df = data.copy()
for col in df.columns:
    df[f"{col}_pred"] = df[col].shift(-future_days)

df.dropna(inplace=True)
df.head()

from sklearn.ensemble import RandomForestRegressor

models = {}

for col in data.columns:
    X = df[[col]]
    y = df[f"{col}_pred"]

    model = RandomForestRegressor(n_estimators=200)
    model.fit(X, y)

    models[col] = model

print("Models trained for:", models.keys())

!pip install plotly --quiet

!pip install streamlit pyngrok yfinance scikit-learn plotly beautifulsoup4 requests

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import numpy as np
# import yfinance as yf
# import requests
# from bs4 import BeautifulSoup
# from sklearn.ensemble import RandomForestRegressor
# import plotly.graph_objects as go
# from datetime import timedelta
# 
# st.set_page_config(layout="wide")
# st.title("Indian Commodities Live Dashboard & Prediction")
# 
# # ----------------------------- #
# # -------- SCRAPERS ---------- #
# # ----------------------------- #
# 
# def scrape_gold_24k_10g_delhi():
#     try:
#         url = "https://www.goodreturns.in/gold-rates/delhi.html"
#         soup = BeautifulSoup(requests.get(url, timeout=10).text, "html.parser")
#         table = soup.find("div", {"class": "gold_silver_table"})
#         for line in table.text.split("\n"):
#             if "24 Carat" in line and "10g" in line:
#                 return float(line.split("₹")[1].replace(",", "").strip())
#     except:
#         return None
# 
# 
# def scrape_silver_1kg_delhi():
#     try:
#         url = "https://www.goodreturns.in/silver-rates/delhi.html"
#         soup = BeautifulSoup(requests.get(url, timeout=10).text, "html.parser")
#         table = soup.find("div", {"class": "gold_silver_table"})
#         for line in table.text.split("\n"):
#             if "1 Kg" in line and "₹" in line:
#                 return float(line.split("₹")[1].replace(",", "").strip())
#     except:
#         return None
# 
# 
# # ----------------------------- #
# # ------- MARKET DATA -------- #
# # ----------------------------- #
# 
# @st.cache_data(ttl=3600)
# def load_data():
#     tickers = {
#         "GC=F": "Gold_USD",
#         "SI=F": "Silver_USD",
#         "CL=F": "Crude",
#         "NG=F": "NatGas",
#         "HG=F": "Copper",
#         "USDINR=X": "USDINR",
#     }
# 
#     df = pd.DataFrame()
#     for t, name in tickers.items():
#         df[name] = yf.download(t, period="1y", interval="1d")["Close"]
# 
#     df.dropna(inplace=True)
#     return df
# 
# 
# data = load_data()
# 
# # ----------------------------- #
# # ----- USD → INR MODEL ------ #
# # ----------------------------- #
# 
# def gold_inr_10g(usd_oz, usd_inr):
#     return (usd_oz * usd_inr * 10) / 31.1035
# 
# 
# def silver_inr_kg(usd_oz, usd_inr):
#     return (usd_oz * usd_inr * 1000) / 31.1035
# 
# 
# data["Gold_Model"] = gold_inr_10g(data["Gold_USD"], data["USDINR"])
# data["Silver_Model"] = silver_inr_kg(data["Silver_USD"], data["USDINR"])
# data["Crude_Model"] = data["Crude"] * data["USDINR"]
# data["NatGas_Model"] = data["NatGas"] * data["USDINR"]
# data["Copper_Model"] = data["Copper"] * data["USDINR"]
# 
# # ----------------------------- #
# # ----- FEATURE ENGINEERING -- #
# # ----------------------------- #
# 
# def make_features(df, col):
#     d = df.copy()
# 
#     for i in range(1, 6):
#         d[f"lag_{i}"] = d[col].shift(i)
# 
#     d["roll_mean"] = d[col].rolling(3).mean()
#     d["roll_std"] = d[col].rolling(3).std()
#     d["USDINR_feat"] = d["USDINR"]
#     d["Crude_feat"] = d["Crude_Model"]
# 
#     d["Target"] = d[col].shift(-1)
#     d.dropna(inplace=True)
# 
#     return d
# 
# 
# # ----------------------------- #
# # -------- ML MODEL ---------- #
# # ----------------------------- #
# 
# def train_predict(df, col):
#     feat = make_features(df, col)
# 
#     features = [
#         col, "lag_1", "lag_2", "lag_3", "lag_4", "lag_5",
#         "roll_mean", "roll_std",
#         "USDINR_feat", "Crude_feat"
#     ]
# 
#     X = feat[features]
#     y = feat["Target"]
# 
#     model = RandomForestRegressor(
#         n_estimators=400,
#         max_depth=12,
#         random_state=42
#     )
#     model.fit(X, y)
# 
#     last = feat.iloc[-1][features].values.reshape(1, -1)
# 
#     preds, dates = [], []
#     base = df.index[-1]
# 
#     for i in range(5):
#         p = model.predict(last)[0]
#         preds.append(p)
#         dates.append(base + timedelta(days=i + 1))
# 
#         last = np.roll(last, 1)
#         last[0][0] = p
# 
#     return preds, dates
# 
# 
# # ----------------------------- #
# # ----------- UI ------------- #
# # ----------------------------- #
# 
# commodity_map = {
#     "Gold (24K, ₹/10g)": "Gold_Model",
#     "Silver (₹/kg)": "Silver_Model",
#     "Crude Oil": "Crude_Model",
#     "Natural Gas": "NatGas_Model",
#     "Copper": "Copper_Model",
# }
# 
# choice = st.selectbox("Select Commodity", list(commodity_map.keys()))
# col = commodity_map[choice]
# 
# # Live Price
# if "Gold" in choice:
#     live = scrape_gold_24k_10g_delhi()
#     price = live if live else data[col].iloc[-1]
#     st.metric("Delhi Gold 24K (10g)", f"₹ {price:,.2f}")
# 
# elif "Silver" in choice:
#     live = scrape_silver_1kg_delhi()
#     price = live if live else data[col].iloc[-1]
#     st.metric("Delhi Silver (1 Kg)", f"₹ {price:,.2f}")
# 
# else:
#     price = data[col].iloc[-1]
#     st.metric("Current Price (INR)", f"₹ {price:,.2f}")
# 
# # Prediction
# preds, dates = train_predict(data, col)
# 
# # Graph
# last10 = data.tail(10)
# 
# fig = go.Figure()
# fig.add_trace(go.Scatter(
#     x=last10.index, y=last10[col],
#     mode="lines+markers", name="Last 10 Days"
# ))
# fig.add_trace(go.Scatter(
#     x=dates, y=preds,
#     mode="lines+markers", name="Next 5 Days Prediction"
# ))
# 
# fig.update_layout(
#     title=choice,
#     xaxis_title="Date",
#     yaxis_title="Price (INR)"
# )
# 
# st.plotly_chart(fig, width="stretch")
# 
# # Table
# st.subheader("Next 5 Days Predicted Prices")
# st.dataframe(pd.DataFrame({
#     "Date": dates,
#     "Predicted Price (INR)": preds
# }))
#

!ngrok config add-authtoken 39WpPhs0tY7IvzaO9tec98G5S3q_3k9RKFqyxCApfhE6XPWnR

!pkill -f streamlit
!pkill -f ngrok

get_ipython().system_raw('streamlit run app.py --server.port 8501 &')

from pyngrok import ngrok
public_url = ngrok.connect(8501)
print(public_url)